{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "6770aad7-0d51-4bf4-a4e8-4530307ecd9f",
      "cell_type": "code",
      "source": "# imports\n\nimport os\nfrom dotenv import load_dotenv\nimport gradio as gr\nimport litellm",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0ae8c343-014b-44d2-96db-9db2d21be601",
      "cell_type": "code",
      "source": "# This one line reads your .env file and loads your GEMINI_API_KEY\nload_dotenv()\n\nprint(\"✅ API Key loaded securely from .env file.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3dd80462-4baf-4d5c-9c13-11855d614392",
      "cell_type": "code",
      "source": "# Initialize\nMODEL = 'gemini/gemini-1.5-flash'",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1e17bda9-74c3-4c0a-a93c-9377497aeaae",
      "cell_type": "code",
      "source": "system_message = \"You are a helpful assistant\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "909d7cbc-3051-47cc-96e5-0354a9dae4cc",
      "cell_type": "code",
      "source": "def chat(message, history):\n    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n\n    print(\"History is:\")\n    print(history)\n    print(\"And messages is:\")\n    print(messages)\n\n    stream = litellm.completion(model=MODEL, messages=messages, stream=True)\n\n    response = \"\"\n    for chunk in stream:\n        response += chunk.choices[0].delta.content or ''\n        yield response",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "41423e8d-3deb-4b3a-9ed8-5a4d28f39453",
      "cell_type": "code",
      "source": "# Gradio magic \n# gr.ChatInterface(fn=chat, type=\"messages\").launch() #chatinterface only work when function is written in chat(message,history) format",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a15befc0-88a4-4575-9395-6035470d7804",
      "cell_type": "code",
      "source": "# now Multi-shot promt\nsystem_message = \"You are a helpful assistant in a bookstore. You should gently encourage customers to explore titles \\\n    that are currently on sale. \\\n    Fiction books are 60% off, and most other genres are 50% off. \\\n    For example, if a customer says 'I'm looking to buy a novel', you could reply something like,\\\n    'Excellent choice — we have a wide selection of novels, including many featured in our current discount event.\\\n    ' If the customer seems unsure, kindly suggest popular or discounted fiction titles to help them decide.\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2dc30fe6-7072-48f6-a812-35120be86688",
      "cell_type": "code",
      "source": "def chat(message, history):\n    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n\n    stream = litellm.completion(model=MODEL, messages=messages, stream=True)\n\n    response = \"\"\n    for chunk in stream:\n        response += chunk.choices[0].delta.content or ''\n        yield response",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "99b41909-bf18-40ab-ad33-e5377ed6d4cb",
      "cell_type": "code",
      "source": "# gr.ChatInterface(fn=chat, type=\"messages\").launch()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4d48a93c-1c30-4fd7-a906-a814412619a4",
      "cell_type": "code",
      "source": "system_message += \"\\nIf the customer asks for children's books, you should respond that children's books are not on sale today, \\\nbut kindly remind them to check out our fiction section, where many titles are currently 60% off.\"\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ac44b6a7-65ee-45cc-af54-af8fc4b4682f",
      "cell_type": "code",
      "source": "#gr.ChatInterface(fn=chat, type=\"messages\").launch()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e98faaa2-5f98-4507-b990-861e4cc1e7d5",
      "cell_type": "code",
      "source": "# reply for a perticular keyword.\ndef chat(message, history):\n\n    relevant_system_message = system_message\n    if 'newspaper' in message:\n        relevant_system_message += \" The store does not sell newspaper ; if you are asked for newspaper, be sure to point out other items on sale.\"\n    \n    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n\n    stream = litellm.completion(model=MODEL, messages=messages, stream=True)\n\n    response = \"\"\n    for chunk in stream:\n        response += chunk.choices[0].delta.content or ''\n        yield response",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4366e91e-f638-43ee-9e89-32fc590eeaf4",
      "cell_type": "code",
      "source": "gr.ChatInterface(fn=chat, type=\"messages\").launch()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}